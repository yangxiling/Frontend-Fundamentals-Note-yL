### :question: 1.如何通过 一个 不均匀的硬币得到公平的结果？

&emsp;:pencil2: A：抛出一次硬币正面朝上的概率是p，反面朝上的概率是(p-1);

|      |     0     |        1        |
| :--: | :-------: | :-------------: |
|  0   |     p     |    p*（p-1）    |
|  1   | （p-1）*p | （p-1）*（p-1） |

根据表格可以看出：（0，1）和（1，0）两种情况的概率是相同的。所以连续抛两次硬币，如果得到相同的结果就重新抛两次。出现 “正 反” 或 “反 正”情况就获得两个相等概率的事件，结果就是公平的。

#​#​#​ :question:1.1 给定一个 foo 函数，60%的概率返回0，40%的概率返回1，如何利用 foo 函数实现一个 50% 返回 0 的函数？

&emsp;:pencil2: A:获得（1，0）和（0，1）的概率是一样的，就可构造出50%概率，所以出现这两种情况就返回。出现（0，0）和（1，1）结果就抛弃重新开始。

```javascript
function half01(){
  while(true){
     let a = foo();
 		 let b = foo();
    if(a!=b) return a&b;
   }
}
```

### :question:2.有序链表插入的时间复杂度是多少？

&emsp; :pencil2: A：因为是有序链表，需要迭代找到合适的位置，所以插入的时间复杂度是O(n)  


### :question:3.常用的排序方式有哪些，时间复杂度是多少？

&emsp;:pencil2: A:[冒泡](./src/bubbleSort.js)、[选择](./src/selectionSort.js)、[插入](./src/insertSort.js)的时间复杂度都是O(n²)；[归并](./src/mergeSort.js)、[希尔](./src/shellSort.js)、[快速](./src/quickSort.js)的时间复杂度是O(nlogn)  


### :question:4.使用递归及非递归两种方式实现快速排序

&emsp; :pencil2: A：[快速排序的两种方法](./src/quickSort.js)  


### :question:4. 快速排序的空间复杂度是多少？时间复杂度的最好最坏的情况是多少，有哪些优化方案？

&emsp;:pencil2: A: 空间复杂度：平均情况O(logn)。空间复杂度主要是递归造成的栈空间的使用。

快速排序的时间复杂度O(nlogn)。最好的情况递归树的深度是O(log2n),即元素均匀分为两个子序列，时间复杂度O(nlogn)；最坏情况元素都分到一个子序列，另一个序列为空，时间复杂度O(n²)。

**优化方案：主要从&emsp;pivot的选取、处理重复元素的问题、优化小数组的效率&emsp;这几个方面考虑**

1.合理pivot的选取:直接选择分区的第一项或者是最后一项是很不合理的。对于已经排好序或者接近排好序的数组会直接进入最差的情况，时间复杂度O(n²)

**1.pivot选取理想的情况是：**让分区中比pivot小的元素数量和比pivot大的元素数量差不多。较常用的做法是三数取中，  即从第一项、最后一项和中间项 取中位数作为pivot。当然这并不能完全避免最差的情况发生，所以很多时候会采取更小心、更严谨的pivot选择方案（对于大数组特别重要）。比如把数组分成三段，每段用三数取中找出中位数，再从得到的中位数中找出中位数。

如果是数量级很大的数组，可以每隔200左右（不固定）选取一个元素，找出其中的中位数，再加入首位两个元素，从这三个元素中找出中位数。（javascript v8引擎中的一个选取pivot方法）

**2.处理重复元素的问题：**如果一个大数组中重复元素很多，也会使快排进入最差的情况。可以创建一个数组pivotSame专门存放与pivot相同的元素，最后拼接left、pivotSame和rigth。

**3.优化小数组的效率：**对于数组的规模很小快排可能并没有优势，所以可以用插入排序替代。

（还有方案：递归优化-->尾递归。javascript没有，但是可以用循环变相手动实现尾递归优化同样的效果[v8 案例]）  


### :question:5.什么是排序算法中的稳定性？

&emsp;:pencil2:A:如果一个待排序的序列中，有两个相等的数值，排序前 A[i]的位置在A[j]前面，排序后A[i]的位置跑到了A[j]的后面，那么这种排序方式就是不稳定的。  


### :question:6.不稳定的排序算法有哪些？

&emsp;:pencil2:A:稳定的排序：冒泡、插入、归并。

不稳定的排序：选择、希尔、快排、堆排序。  


#​#​#​ :question:7.10亿个数中如何高效地找到最大的一个数以及最大的第 K 个数 ?

&emsp;:pencil2:A:方法1：构建一个k个数的最小堆，然后遍历，如果遇到比堆顶大的数就替换，然后调整堆结构使之仍是最小堆。把10亿个数存放到1000个文件里，分别在每个文件中找出前k个大的数，然后放在一起在找出第k大的数。建堆堆化的时间复杂度O(mlogm)。总体时间复杂度O(nlogm),n是数据的总数（找最大的一个数就取一定数量的值构建最大堆，最后取堆顶的值）

最好的解决方案是：[快速选择排序方法](./src/quickSlect.js)  


### :question: 8.堆排序的时间复杂度是多少？说几个堆排序的应用场景

&emsp;:pencil2:A:O(nlogn)，构建堆的时间复杂度O(n)，堆化的时间复杂度O(nlogn)，总的时间复杂度O(nlogn)。求一个大数组中的第k大值或者第k小值。  


#​#​#​ :question:9.如何随机生成不重复的 10个100 以内的数字？

 ```javascript
function uniqueNum(){
  let res = new Set();
  while(res.size < 10){
     const num = ParseInt(Math.random()*100);
    if(!res.has(num)){
      res.add(num);
    }
  }
  return res;
}
 ```



### :question: 10.如何实现大数运算?

&emsp;:pencil2:A：可以把大数存为一个数组序列，然后对数组挨个取值进行运算。

### :question:两个文件包含无序的数字，数字的大小范围是0-500w左右。如何求两个文件中的重复的数

```javascript
//求两个文件的交集 将第一个文件建成一个Set()结构。
//方法一：
function intersection(arrfile1,arrfile2){
	let map = new Map(arrfile);
  for(let v of arrfile1){
    if(map.has(v)){
      map.set(v,map.get(v)+1)
    }else{
      map.set(v,1)
    }
  }
  let intersect = [];
  for(let v of arrfile2){
    if(map.has(v)&&map.get(v)>0){
      map.set(v,map.get(v)-1)
      intersect.push(v)
    }
  }
  return intersect;
}
//方法二：对两个数组排序，然后定义两个指针
```



### :question: 1000台 机器，每台机器 1000个 文件，每个文件存储了 10亿个 整数，如何找到其中最小的 1000个 值？

&emsp;:pencil2:A：对每个文件的10亿个数据分成几个数组，对每个数组用1000个值的最小堆求出其中最小的1000个数，然后再从所有求出的前1000小的数中求出最小的1000个值。自底向上每个文件都这样处理，然后求出最后的1000个最小值。



### :question:如何从一个数组输出随机数组

```javascript
function getRandomArrayElement(arr,count){
  let shuffled = [];
  let tArr = arr.concat([]);
  let i = arr.length,c = count+1;
  while(--c){
    let index = Math.floor((c+1)*Math.random());
    shuffled.push(tArr[index]);
    tArr.splice(index,1);
  } 
  return shuffled;
}
```

### :question: 10亿个url 找出出现频率最高的100个URL

&emsp;:pencil2:A：首先，主体思路就是构建HashMap，然后统计每个url出现的次数。根据统计出来的次数值构建一个最小堆，找出其中出现频率最高的100个URL。

当然，如果数据太大，硬件条件是有限的，可以先将大的数据分割成合适合适数量的小文件。然后分别统计，最后汇总统计，最后找出想要的结果。



### :question:给定 100G 的 URL 磁盘数据，使用最多 1G 内存，统计出现频率最高的 Top K 个 URL:

&emsp;:pencil2:A：1、分治-大化小；2、构建哈希映射；3、排序

首先，主体思路就是。根据统计出来的次数值构建一个最小堆，如果有找出其中出现频率最高的100个URL。

1、数据太大，硬件条件是有限，先将大的数据分割成合适数量的小文件。

2、构建Map，key存URL，value存url出现的次数。根据统计出来的value，构建一个k个数的最小堆（如果有值大于堆顶，替换堆顶，重新调整堆结构。直到找出前k个值）。每个文件都如此。

3、将每个文件统计结果汇总，在进行一轮堆排序，找出出现频率最高的 Top K 个 URL

（看看mapreduce介绍。**MapReduce**[[1\]](https://zh.wikipedia.org/wiki/MapReduce#cite_note-MapReduce-1)是[Google](https://zh.wikipedia.org/wiki/Google)提出的一个[软件架构](https://zh.wikipedia.org/wiki/软件架构)，用于大规模数据集（大于1[TB](https://zh.wikipedia.org/wiki/Terabyte)）的[并行运算](https://zh.wikipedia.org/wiki/並行運算)。概念“Map（映射）”和“Reduce（归纳）”，及他们的主要思想，都是从[函数式编程语言](https://zh.wikipedia.org/wiki/函数式编程语言)借鉴的，还有从[矢量编程语言](https://zh.wikipedia.org/w/index.php?title=矢量编程语言&action=edit&redlink=1)借来的特性）

###  :question: 给定一个包含 40亿 个无符号整数的大型文件，使用最多 1G 内存，对此文件进行排序

&emsp;:pencil2:A：首先，构建HashMap  把所有的数出现次数都统计出来，HashMap中key存放数值，value存放出现的次数。然后再根据统计出来的HashMap对数字排序。

然后考虑，已知内存不能一次处理这么数。因为一个int占 4B内存，哈希表的一个键值对占8B。1G有1G=1024MB=1024* 1024KB = 1024* 1024*1024B，那么1G就可以存储 1亿多条记录。所以开始要对这个大型文件进行分割，以最坏的情况每个数都不相同来计算，分成40个小文件，分别统计，然后合并统计结果，在对数据排序。



### :question:实现 LRU 算法，实现带有过期时间的 LRU 算法

